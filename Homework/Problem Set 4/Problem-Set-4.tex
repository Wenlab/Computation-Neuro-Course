\documentclass{article}
\usepackage{amsmath, amssymb}
\usepackage{hyperref}
\usepackage{graphicx}
\title{Problem Set 3}
\date{Due Wednesday, Dec 22, 2021}

\begin{document}
\maketitle

\section*{Optimal Receptive Field in 1-Dimensional World}
We will follow our lecture on the efficient coding principle, which allows us to derive the optimal synaptic weight $W$ (also called receptive field for the output neurons) that maximizes the mutual information in the presence of noise. Go through page 5-9 in the lecture note carefully. Now imagine a 1-dimensional visual world on a circle with inputs that are correlated according to 
\begin{equation}
c(n.m) = \langle x(n)x(m)\rangle = c(n-m) = \exp(-\frac{|n-m|}{D}), 
\end{equation}
where $n$ is a spatial index running from 1 to $N$ (note: with periodic boundary conditions, $|n-m|$ for distances larger than $N/2$ should be replaced by $N-|n-m|$). The input contains additional spatially uncorrelated input noise with variance $\sigma_z^2$.  We want to find the shape of the receptive fields, namely the functional form of $W$ that are optimized for this world.
\begin{enumerate}
\item[(a)] Using my lecture note as a guide, show that  in the spatial frequency domain, the optimal receptive field (or filter) $W(k)$ is given by the equation
\[
W^2(k) = \frac{\sigma_\eta^2}{\sigma_z^2}\left(\frac{1}{2}\left[\frac{c(k)}{c(k) + \sigma_z^2}\left(1+\sqrt{1+\frac{\mu}{c(k)}}\right)\right] - 1\right),
\]
where $c(k)$ is power spectrum of the visual inputs, $\sigma_\eta^2$ is the output noise. We will set $\sigma_\eta^2 = 1$ in this model. Please recall my lectures what is a power spectrum and how it is related to the eigenvalues of the input covariance matrix, which happens to be a circulant matrix in our 1-dimensional visual world. $\mu$ is a term involving the lagrange multiplier $\lambda$. Here, we make a specific requirement that the total variance (or power) of the outputs $\mathbf{y}$ is independent of input noise, and is set as a constant. If you cannot derive this result, proceed to the next question.

\item[(b)] Find the dependence of $W(k)$ on $C(k)$ analytically, in the limits of small and large input noise $\sigma_z^2$. Interpret your results.  \textbf{Guide}: In order to derive these limits, you will need to consider how $\mu$ varies with $\sigma_z^2$ so that the total output variance remains a constant. It can be shown that for small noise $\mu \propto \sigma_z^2$, where as for large noise,  $\mu \propto \sigma_z^4$.

\item[(c)] Numerically Fourier transform $W(k)$ to calculate the spatial shape of the optimal filters. Use $N=401$ and $D=30$ and study different values of noise, $\sigma_z^2$ (given in the script file). Qualitatively explain your results, by plotting the spectrum $W(k)$ vs. $k$ and $W(n)$ vs. $n$ for different values of input noise. Compare these numerical results with your analytical predictions from (b). You will find the matlab functions fft and ifft useful.  
\end{enumerate}


\section*{A toy model of neural integrator}
An animal moves on a one-dimensional track. In order to navigate properly (e.g., to find its way back home) the brain must compute the 'on line' position of the animal given sensory information about its velocity. We will assume that the position is computed by means of a network composed of two neurons, whose input is the animal's velocity. The network obeys the following equations:
\begin{equation}
\begin{aligned}
\tau \frac{dx}{dt}=-ax-2y+\tau V(t); \\
\tau \frac{dy}{dt}=-(3-a)x-y-\tau V(t)
\end{aligned}
\end{equation}
where the value of $x(t)$ represents the estimated position of the animal at time $t$. 

\begin{enumerate}
\item[(a)] Study the dynamics of the network for constant velocity, i.e., $V(t)=V_0$ for all $t>0$:
First, find the fixed point of the network and the region of values of the parameter a for which this fixed point is stable. Next, write down the solution for $x(t)$ given that $(x(0),y(0))=(0,0)$ and explain what happens as time increases.
\item[(b)] Position Estimation. Assume that at $t = 0$, the animal starts out at the origin, and begins moving at a constant velocity $V(t) = 0.1$ m/s. Use $\tau =100$ ms. If the system acted as a perfect integrator of the velocity, the expected position at $t=10$ s would be 1 m. Is there a parameter choice (for parameter a) for which this system acts as a perfect integrator? (If so, take any appropriate limits to prove it.) For what range of parameters does the system act as a leaky integrator, i.e., the readout is within 1 cm error of the estimated position from a perfect integrator after 10 seconds? What happens to $x(t)$ when $a$ is outside this range?
\end{enumerate}



\section*{Ring network}
Consider the ring network model we discussed in the class
\begin{equation}
\tau \frac{du_i}{dt} = -u_i + F\left(\sum_{j=1..N} w_{ij}u_j+ I_i^0\right), \label{ring equation}
\end{equation}
where $F(x) = [x]_+$ is a rectified linear function and the weights between the neurons are determined by their angular difference and thus are translational invariant. 
\begin{equation}
w_{ij} = \frac{1}{N} J(\theta_i - \theta_j),
\end{equation}
where $\theta_i = -\pi+ \frac{2\pi i}{N}$ and $J$ is a $2\pi$ periodic function, and  $I_i^0$ is also a periodic $2\pi$ function. In the continuous limit, we have 
\begin{equation}
\tau \frac{\partial u(\theta, t)}{\partial t} = -u(\theta, t) + \left[\frac{1}{2\pi}\int_{-\pi}^{\pi} J(\theta - \theta') u(\theta', t) d\theta' + I^0 (\theta)\right]_+,
\end{equation}


\begin{enumerate}
\item[(a)] If the connectivity matrix $J$ is translational invariant and symmetric, prove that the eigenfunctions of $J$ are Fourier basis, namely 
\begin{eqnarray}
\frac{1}{2\pi}\int_{-\pi}^{\pi} d\theta' J(\theta - \theta')e_\mu(\theta') = \lambda_\mu e_\mu(\theta) \\
e_\mu \sim \cos(\mu\theta) + \sin(\mu\theta),
\end{eqnarray}
where $\mu=0,1,2,...$. Find out the correct normalization factor for the eigenfunctions. The corresponding eigenvalues of the the connectivity matrix can be viewed as the Fourier transform $J(\theta)$, namely 
\begin{equation}
\lambda_\mu = \frac{1}{2\pi}\int_{-\pi}^{\pi} J(\theta) \cos(\mu \theta)d\theta
\end{equation}
\item[(b)] In the spirit of the linear recurrent network model we discussed in the class, derive the general solution of the $linear$ ring network by assuming that  $F(x) = x$ instead of a rectified linear network. In the class, we have considered a simple form of the connectivity matrix, 
\begin{eqnarray}
J(\theta) = J_0 + J_1\cos\theta \\
I_i^0(\theta) = I_0 + I_1\cos(\theta - \theta_0)
\end{eqnarray}
Discuss the stability of a linear ring network in this simple case.
\item[(c)] Consider the special case $I_1=0$, so that each neuron receives the same homogeneous inputs and $F(x) = [x]_+$. A naive solution is that the population neural activity is homogeneous : all neurons have the same activity. Show that this naive solution is unstable when $J_1 >2$.
\item[(d)] We show in the class that a marginal stable solution is the emergence of a bump, namely, $u(\theta) = [u_1\cos (\theta) + u_0]_+$. Please show that the bump can actually appear anywhere, namely $u(\theta) = [u_1\cos (\theta - \phi) + u_0]_+$, where $\phi$ is arbitrary. 
\item[(e)] Draw the phase diagram on the $J_0-J_1$ plane. Discuss and plot in what region, the system is marginally stable?  In what region, the system exhibits homogeneous activity? In what region, the system is unstable?
\item[(f)] Now consider some tiny modulatory input with $0 < I_1 \ll I_0$ and $J_1 > 2$. Show that in this case, the location of the peak of the stationary activity is not arbitrary, but aligned to the stimulus angle $\theta_0$.
\item[(g*)] Add to the connectivity matrix a term $\frac{J_1}{N}\gamma \sin(\theta_i - \theta_j)$, where $|\gamma|\ll 1$. Show that there is a solution with the form
\begin{equation}
u(\theta, t) = f(\theta - \omega t), \label{travelling wave}
\end{equation}
where  $f(\theta)$ is the steady state activity profile calculated in the class for $\gamma = 0$  and the angular velocity satisfies  
\begin{equation}
\omega = \frac{\gamma}{\tau}
\end{equation}
\end{enumerate}
\textbf{Last question is a bonus. Here is some specific guide:}
\\
A. Assume a traveling profile of the form of \ref{travelling wave} (for now just use an arbitrary profile $f(\theta)$ ) and insert it into the two sides of \ref{ring equation}. Express the RHS in terms of the order parameters as was done in the class. Expand the RHS in powers of $\gamma$ and keep only terms up to linear in $\gamma$.
\\
B. Show that if $f(\theta)$ is the profile for $\gamma = 0$ the dynamic equations \ref{ring equation} are satisfied. 



\end{document}